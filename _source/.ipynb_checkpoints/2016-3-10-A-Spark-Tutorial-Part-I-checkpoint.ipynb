{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "title: \"A Spark Tutorial: Part I\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Apache Spark](https://spark.apache.org/) is an open source cluster computing framework. It aims to make it simpler to write programs that run in parallel across many nodes in a cluster of computers. It also provides a higher level API to work with distributed data. It is similar to other ditributed processing frameworks such as [Apache Hadoop](http://hadoop.apache.org/); however, the underlying architecture is somewhat different.\n",
    "\n",
    "You can check out this [page](http://spark.apache.org/community.html#history) for more background on Spark.\n",
    "\n",
    "## Why Spark?\n",
    "As declared on its webpage, Spark\n",
    "\n",
    "> Run programs up to 100x faster than Hadoop MapReduce in memory, or 10x faster on disk.\n",
    "\n",
    "In addition\n",
    "\n",
    "* You can write Spark applications quickly in either Java, Scala, Python or R.\n",
    "* You can combine SQL, machine learning ([MLlib](https://spark.apache.org/mllib/)), graph computation([GraphX](https://spark.apache.org/graphx/)) and Spark Streaming seamlessly in the same application.\n",
    "* You can run Spark either on your own computer, on Hadoop YARN, on Apache Mesos, or in the cloud ([Amazon EC2](https://aws.amazon.com/ec2/), [Amazon EMR](https://aws.amazon.com/elasticmapreduce/)).\n",
    "* Everyone is using it! Check out this [page](https://cwiki.apache.org/confluence/display/SPARK/Powered+By+Spark) for a list of companies and organizations creating products and projects for use with Apache Spark.\n",
    "\n",
    "## Setting up Spark locally\n",
    "Spark runs in four modes: (1) the standalone local mode; (2) the standalone cluster mode; (3) using [Mesos](http://mesos.apache.org/); (4) Using [YARN (Hadoop NextGen)](http://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/YARN.html). In this post, I will introduce how to set up the standalone local mode on your own computer.\n",
    "\n",
    "* First, you need to have [Java](https://java.com/en/download/manual.jsp) installed on your computer.\n",
    "* Download the [Spark binaries](http://spark.apache.org/downloads.html). A package pre-built for Hadoop is recommended unless you want to build Spark against a specific Hadoop version. Save the unziped files in, for example, **C:\\spark**. Try run **C:\\spark\\bin\\spark-shell.cmd** which may produce some errors if you are using Windows (see next step to solve this problem).\n",
    "\n",
    "{% highlight bash %}\n",
    "cd C:\\spark\\bin\n",
    "spark-shell\n",
    "{% endhighlight %}\n",
    "\n",
    "* Windows users:\n",
    "    * Make sure **C:\\Windows\\System32** is in PATH in environment variables.\n",
    "    * [Download](https://github.com/steveloughran/winutils/raw/master/hadoop-2.6.0/bin/winutils.exe) the 64-bit **winutils.exe**, save **winutils.exe** into a folder like **C:\\hadoop\\bin** and set your environment variable `HADOOP_HOME` to **C:\\hadoop** (NOT C:\\hadoop\\bin). Also, set permision to **C:\\tmp\\hive**, which is created by Hive when starting the **spark-shell.cmd**.\n",
    "    \n",
    "{% highlight bash %}\n",
    "set HADOOP_HOME=C:\\hadoop\n",
    "echo %HADOOP_HOME%\n",
    "%HADOOP_HOME%\\bin\\winutils.exe chmod 777 \\tmp\\hive\n",
    "%HADOOP_HOME%\\bin\\winutils.exe ls \\tmp\\hive\n",
    "{% endhighlight %}\n",
    "\n",
    "* Now, re-run the **spark-shell.cmd** and it should work as expected.\n",
    "* You can run the example to test the successful setup.\n",
    "\n",
    "{% highlight bash %}\n",
    "run-example org.apache.spark.examples.SparkPi\n",
    "{% endhighlight %}\n",
    "\n",
    "If everything goes well, you should see something similar to\n",
    "\n",
    "{% highlight text %}\n",
    "16/03/10 20:25:51 INFO DAGScheduler: Job 0 finished: reduce at SparkPi.scala:36, took 1.596556 s\n",
    "Pi is roughly 3.14358\n",
    "{% endhighlight %}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
